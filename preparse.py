#######################################################################
# Sort paperauthors
import pandas as pd

#######################################################################
# Get the subset of authors that are found in paperauthors
# I do a few things to cut down the size of PaperAuthors because I'm
# primarily working on a wimpy laptop
PaperAuthor = pd.read_csv("PaperAuthor.csv")
PaperAuthor = PaperAuthor.drop(['Name', 'Affiliation'], axis=1)
PaperAuthor.to_csv("PaperAuthor2.csv")

# Now get only the authors that are in paperauthors
PaperAuthor = pd.read_csv("PaperAuthor2.csv", index_col=0)
with open('Author.csv', 'r') as fin, open('Author2.csv', 'w') as fout:
    fout.write("Id,Name,Affiliation\n")
    fin.readline()
    authors = set(PaperAuthor['AuthorId'].values)
    for line in fin:
        items = line.split(",")
        if int(items[0]) in authors:
            fout.write(line)

########################################################################
# AuthorsGroups - the author_groups.csv file is generated by author_groups.py.
# It finds repeated papers duplicates and collects all the authors for these papers into an "author group".
authors = pd.read_csv("Author2.csv", index_col=0)
agroups = pd.read_csv("author_groups.csv")
agrps = authors.drop(['Name', 'Affiliation'], axis=1)
agrps['agrps'] = None

# For each author, find the author groups he/she is a member of
for aid in sorted(set(agroups['authorid'].values)):
    agrps.loc[aid, 'agrps'] = agroups['authorgroup'][agroups['authorid'] == aid].values
agrps = agrps[pd.notnull(agrps['agrps'])]

# Print out the dataframe, keyed on authorID and containing lists of author groups
agrps.to_csv("Author8a6.tsv", sep="\t")

